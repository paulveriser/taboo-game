{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1.1.1: There is a statistically significant correlation between contextual understanding rating and accuracy of guesses for groups of concrete, abstract, emotional words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman's Rank-Order Correlation Coefficient: 0.6278998670622327\n",
      "P-Value: 7.152130831084848e-41\n",
      "There is a statistically significant correlation between contextual understanding rating and accuracy of guesses for groups of concrete, abstract, emotional words.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter rows based on wordGroup\n",
    "word_groups_to_include = ['simple', 'abstract', 'emotion']\n",
    "filtered_df = df[df['wordGroup'].isin(word_groups_to_include)]\n",
    "\n",
    "contextual_rating = filtered_df['rating']\n",
    "accuracy = filtered_df['guessed']\n",
    "\n",
    "#Calculate point-biserial Spearmann correlation\n",
    "correlation_coefficient, p_value = stats.spearmanr(contextual_rating, accuracy)\n",
    "\n",
    "#Print results\n",
    "print(f\"Spearman's Rank-Order Correlation Coefficient: {correlation_coefficient}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant correlation between contextual understanding rating and accuracy of guesses for groups of concrete, abstract, emotional words.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant correlation between contextual understanding rating and accuracy of guesses for groups of concrete, abstract, emotional words.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1.1.2: There is a statistically significant correlation between contextual understanding rating and accuracy of guesses for groups of IT words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman's Rank-Order Correlation Coefficient for low IT knowledge group: 0.6768207919786114\n",
      "P-Value: 1.9493973440918988e-32\n",
      "There is a statistically significant correlation between contextual understanding rating and accuracy of guesses for group of IT words among people with low IT knowledge.\n",
      "\n",
      "Spearman's Rank-Order Correlation Coefficient for high IT knowledge group: 0.6448059092611391\n",
      "P-Value: 1.5260296987537877e-30\n",
      "There is a statistically significant correlation between contextual understanding rating and accuracy of guesses for group of IT words among people with high IT knowledge.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Calculate the mean of itKnowledge \n",
    "unique_names_df = df.drop_duplicates(subset='Name')\n",
    "mean_it_knowledge = unique_names_df['itKnowledge'].mean()\n",
    "\n",
    "#Separate data based on level of IT knowledge\n",
    "low_it_df = df[df['itKnowledge'] < mean_it_knowledge]\n",
    "high_it_df = df[df['itKnowledge'] > mean_it_knowledge]\n",
    "\n",
    "#Calculate point-biserial Spearmann correlation for group w/ low IT knowledge\n",
    "low_it_contextual_rating = low_it_df['rating']\n",
    "low_it_accuracy = low_it_df['guessed']\n",
    "correlation_coefficient, p_value = stats.spearmanr(low_it_contextual_rating, low_it_accuracy)\n",
    "\n",
    "#Print results\n",
    "print(f\"Spearman's Rank-Order Correlation Coefficient for low IT knowledge group: {correlation_coefficient}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant correlation between contextual understanding rating\" \n",
    "          + \" and accuracy of guesses for group of IT words among people with low IT knowledge.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant correlation between contextual understanding rating\" \n",
    "            +\" and accuracy of guesses for group for groups of IT words among people with low IT knowledge.\")\n",
    "\n",
    "#Calculate point-biserial Spearmann correlation for group w/ high IT knowledge\n",
    "high_it_contextual_rating = high_it_df['rating']\n",
    "high_it_accuracy = high_it_df['guessed']\n",
    "correlation_coefficient, p_value = stats.spearmanr(high_it_contextual_rating, high_it_accuracy)\n",
    "\n",
    "#Print results\n",
    "print(f\"\\nSpearman's Rank-Order Correlation Coefficient for high IT knowledge group: {correlation_coefficient}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant correlation between contextual understanding rating\" \n",
    "          + \" and accuracy of guesses for group of IT words among people with high IT knowledge.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant correlation between contextual understanding rating\" \n",
    "            +\" and accuracy of guesses for group for groups of IT words among people with high IT knowledge.\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1.2.1: There is a statistically significant correlation between contextual understanding rating and TTS for groups of concrete, abstract, emotional words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient: -0.24380955681648733\n",
      "P-Value: 0.0004712358666319909\n",
      "There is a statistically significant correlation between contextual understanding rating and TTS for groups of concrete, abstract, emotional words.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter rows based on wordGroup\n",
    "word_groups_to_include = ['simple', 'abstract', 'emotion']\n",
    "filtered_df = df[df['wordGroup'].isin(word_groups_to_include)]\n",
    "\n",
    "#Filter rows where TTS is not null \n",
    "guessed_true_df = filtered_df[filtered_df['guessed'] == True]\n",
    "contextual_rating = guessed_true_df['rating']\n",
    "TTS = guessed_true_df['timeToSuccess']\n",
    "\n",
    "# Calculate the Pearson correlation coefficient and the p-value\n",
    "correlation_coefficient, p_value = stats.pearsonr(contextual_rating, TTS)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Pearson Correlation Coefficient: {correlation_coefficient}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant correlation between contextual understanding rating\" +\n",
    "            \" and TTS for groups of concrete, abstract, emotional words.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant correlation between contextual understanding rating\" + \n",
    "          \"and TTS for groups of concrete, abstract, emotional words.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1.2.2: There is a statistically significant correlation between contextual understanding rating and TTS for group of IT words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient: -0.26207276942192403\n",
      "P-Value: 0.41058384873962206\n",
      "There is no statistically significant correlation between contextual understanding rating and TTS for group of IT words among people with limited IT knowledge.\n",
      "\n",
      "Pearson Correlation Coefficient: -0.34189028101050317\n",
      "P-Value: 0.06947866946942606\n",
      "There is no statistically significant correlation between contextual understanding rating and TTS for group of IT words among people with good IT knowledge.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Calculate the mean of itKnowledge \n",
    "unique_names_df = df.drop_duplicates(subset='Name')\n",
    "mean_it_knowledge = unique_names_df['itKnowledge'].mean()\n",
    "\n",
    "#Separate data based on level of IT knowledge\n",
    "low_it_df = df[df['itKnowledge'] < mean_it_knowledge]\n",
    "high_it_df = df[df['itKnowledge'] > mean_it_knowledge]\n",
    "\n",
    "#Filter rows based on wordGroup\n",
    "word_groups_to_include = ['IT']\n",
    "\n",
    "filtered_low_it_df = low_it_df[low_it_df['wordGroup'].isin(word_groups_to_include)]\n",
    "filtered_high_it_df = high_it_df[high_it_df['wordGroup'].isin(word_groups_to_include)]\n",
    "\n",
    "#Filter rows where TTS is not null and calculate the Pearson correlation coefficient and the p-value for low IT group \n",
    "guessed_true_low_it_df = filtered_low_it_df[filtered_low_it_df['guessed'] == True]\n",
    "low_it_rating = guessed_true_low_it_df['rating']\n",
    "low_it_TTS = guessed_true_low_it_df['timeToSuccess']\n",
    "\n",
    "correlation_coefficient, p_value = stats.pearsonr(low_it_rating, low_it_TTS)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Pearson Correlation Coefficient: {correlation_coefficient}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant correlation between contextual understanding rating and TTS for group IT words among people with limited IT knowledge.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant correlation between contextual understanding rating and TTS for group of IT words among people with limited IT knowledge.\")\n",
    "\n",
    "#Filter rows where TTS is not null and calculate the Pearson correlation coefficient and the p-value for high IT group \n",
    "\n",
    "guessed_true_high_it_df = filtered_high_it_df[filtered_high_it_df['guessed'] == True]\n",
    "high_it_rating = guessed_true_high_it_df['rating']\n",
    "high_it_TTS = guessed_true_high_it_df['timeToSuccess']\n",
    "\n",
    "correlation_coefficient, p_value = stats.pearsonr(high_it_rating, high_it_TTS)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nPearson Correlation Coefficient: {correlation_coefficient}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant correlation between contextual understanding rating and TTS for group IT words among people with good IT knowledge.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant correlation between contextual understanding rating and TTS for group of IT words among people with good IT knowledge.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2.1: There is a statistically significant difference in the rating of contextual understanding in ChatGPT-generated and human-generated prompts for concrete words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistic: 297.5\n",
      "P-value: 0.0008794839441877213\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "concrete_df = data[data['wordGroup'].isin(['simple'])]\n",
    "\n",
    "gpt_concrete_df = concrete_df[concrete_df['generatedBy'].isin(['gpt'])]\n",
    "human_concrete_df = concrete_df[concrete_df['generatedBy'].isin(['human'])]\n",
    "\n",
    "ChatGPT_rating = gpt_concrete_df['rating']\n",
    "Human_rating = human_concrete_df['rating']\n",
    "\n",
    "#Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(ChatGPT_rating, Human_rating)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2.2: There is a statistically significant difference in the rating of contextual understanding in ChatGPT-generated and human-generated prompts for abstract words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistic: 63.5\n",
      "P-value: 6.4175256917547336e-06\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "abstract_df = data[data['wordGroup'].isin(['abstract'])]\n",
    "\n",
    "gpt_abstract_df = abstract_df[abstract_df['generatedBy'].isin(['gpt'])]\n",
    "unique_name_gpt_df = gpt_abstract_df.drop_duplicates(subset='Name',keep=False)\n",
    "\n",
    "human_abstract_df = abstract_df[abstract_df['generatedBy'].isin(['human'])]\n",
    "unique_name_human_df = human_abstract_df.drop_duplicates(subset='Name',keep=False)\n",
    "\n",
    "#Join two DF based on the same name \n",
    "combined_abstract_df = unique_name_gpt_df.merge(unique_name_human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "ChatGPT_rating = combined_abstract_df['rating_gpt']\n",
    "Human_rating = combined_abstract_df['rating_human']\n",
    "\n",
    "#Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(ChatGPT_rating, Human_rating,alternative='two-sided', mode='approx')\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2.3: There is a statistically significant difference in the rating of contextual understanding in ChatGPT-generated and human-generated prompts for words describing emotional states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistic: 58.0\n",
      "P-value: 5.5679593164750926e-05\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "emotion_df = data[data['wordGroup'].isin(['emotion'])]\n",
    "\n",
    "gpt_emotion_df = emotion_df[emotion_df['generatedBy'].isin(['gpt'])]\n",
    "unique_name_gpt_df = gpt_emotion_df.drop_duplicates(subset='Name', keep = False)\n",
    "\n",
    "human_emotion_df = emotion_df[emotion_df['generatedBy'].isin(['human'])]\n",
    "unique_name_human_df = human_emotion_df.drop_duplicates(subset='Name', keep = False)\n",
    "\n",
    "#Join two DF based on the same name \n",
    "combined_emotion_df = unique_name_gpt_df.merge(unique_name_human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "\n",
    "ChatGPT_rating = combined_emotion_df['rating_gpt']\n",
    "Human_rating = combined_emotion_df['rating_human']\n",
    "\n",
    "#Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(ChatGPT_rating, Human_rating,alternative='two-sided', mode='approx')\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2.4: There is a statistically significant difference in the rating of contextual understanding in ChatGPT-generated and human-generated prompts for IT-specific words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistic: 51.5\n",
      "P-value: 1.334285717309862e-05\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "IT_df = data[data['wordGroup'].isin(['IT'])]\n",
    "\n",
    "gpt_IT_df = IT_df[IT_df['generatedBy'].isin(['gpt'])]\n",
    "human_IT_df = IT_df[IT_df['generatedBy'].isin(['human'])]\n",
    "\n",
    "ChatGPT_rating = gpt_IT_df['rating']\n",
    "Human_rating = human_IT_df['rating']\n",
    "\n",
    "#Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(ChatGPT_rating, Human_rating)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3.1.1: In terms of accuracy, there is a statistically significant difference between the responses to ChatGPT-generated and human-generated prompts for concrete words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test statistic: 9.0\n",
      "P-value: 0.08715855330228806\n",
      "There is no statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter results \n",
    "df = data[data['wordGroup'].isin(['simple'])]\n",
    "\n",
    "gpt_df = df[df['generatedBy'].isin(['gpt'])]\n",
    "human_df = df[df['generatedBy'].isin(['human'])]\n",
    "\n",
    "#Create contigency table\n",
    "combined_df = gpt_df.merge(human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "contingency_table = pd.crosstab(combined_df['guessed_gpt'], combined_df['guessed_human'])\n",
    "\n",
    "# Perform McNemar's test\n",
    "result = mcnemar(contingency_table,exact=True)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"McNemar's test statistic: {result.statistic}\")\n",
    "print(f\"P-value: {result.pvalue}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if result.pvalue < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3.1.2: In terms of accuracy, there is a statistically significant difference between the responses to ChatGPT-generated and human-generated prompts for abstract words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test statistic: 11.0\n",
      "P-value: 0.002887247974285856\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "df = data[data['wordGroup'].isin(['abstract'])]\n",
    "\n",
    "gpt_df = df[df['generatedBy'].isin(['gpt'])]\n",
    "human_df = df[df['generatedBy'].isin(['human'])]\n",
    "\n",
    "combined_df = gpt_df.merge(human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "\n",
    "contingency_table = pd.crosstab(combined_df['guessed_gpt'], combined_df['guessed_human'])\n",
    "\n",
    "# Perform McNemar's test\n",
    "result = mcnemar(contingency_table,exact=True)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"McNemar's test statistic: {result.statistic}\")\n",
    "print(f\"P-value: {result.pvalue}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if result.pvalue < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3.1.3: In terms of accuracy, there is a statistically significant difference between the responses to ChatGPT-generated and human-generated prompts for words describing emotional states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test statistic: 3.0\n",
      "P-value: 0.0025768280029296875\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter results \n",
    "df = data[data['wordGroup'].isin(['emotion'])]\n",
    "\n",
    "gpt_df = df[df['generatedBy'].isin(['gpt'])]\n",
    "human_df = df[df['generatedBy'].isin(['human'])]\n",
    "\n",
    "#Create contigency table\n",
    "combined_df = gpt_df.merge(human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "contingency_table = pd.crosstab(combined_df['guessed_gpt'], combined_df['guessed_human'])\n",
    "\n",
    "# Perform McNemar's test\n",
    "result = mcnemar(contingency_table,exact=True)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"McNemar's test statistic: {result.statistic}\")\n",
    "print(f\"P-value: {result.pvalue}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if result.pvalue < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3.1.4: In terms of accuracy, there is a statistically significant difference between the responses to ChatGPT-generated and human-generated prompts for IT words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test statistic: 2.0\n",
      "P-value: 6.604194641113281e-05\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter results \n",
    "df = data[data['wordGroup'].isin(['IT'])]\n",
    "\n",
    "gpt_df = df[df['generatedBy'].isin(['gpt'])]\n",
    "human_df = df[df['generatedBy'].isin(['human'])]\n",
    "\n",
    "#Create contigency table\n",
    "combined_df = gpt_df.merge(human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "contingency_table = pd.crosstab(combined_df['guessed_gpt'], combined_df['guessed_human'])\n",
    "\n",
    "# Perform McNemar's test\n",
    "result = mcnemar(contingency_table,exact=True)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"McNemar's test statistic: {result.statistic}\")\n",
    "print(f\"P-value: {result.pvalue}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if result.pvalue < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3.2.1: In terms of time to succeed (TTS), there is a satistically significant difference between responses to ChatGPT-generated and human-generated prompts for concrete words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 2.1476602341757767\n",
      "P-Value: 0.04204887704884888\n",
      "There is a statistically significant difference between the paired samples.\n",
      "Wilcoxon statistic: 82.0\n",
      "P-value: 0.029578447341918945\n",
      "There is a statistically significant difference between the paired samples. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter results \n",
    "df = data[data['wordGroup'].isin(['simple'])]\n",
    "\n",
    "#Filter results where TTS is not null\n",
    "true_df = df[df['guessed'] == True]\n",
    "\n",
    "#Filter results according to prompt provider\n",
    "gpt_df = true_df[true_df['generatedBy'].isin(['gpt'])]\n",
    "human_df = true_df[true_df['generatedBy'].isin(['human'])]\n",
    "\n",
    "#Filter TTS \n",
    "combined_df = gpt_df.merge(human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "GPT_TTS = combined_df['timeToSuccess_gpt']\n",
    "Human_TTS = combined_df['timeToSuccess_human']\n",
    "\n",
    "#Perform paired t-test\n",
    "t_statistic, p_value_t = stats.ttest_rel(GPT_TTS, Human_TTS)\n",
    "\n",
    "# Display the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value_t)\n",
    "\n",
    "# Determine if the difference is statistically significant  \n",
    "if p_value_t < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")\n",
    "\n",
    "#Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(GPT_TTS, Human_TTS)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples. \\n\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples. \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3.2.2: In terms of time to succeed (TTS), there is a satistically significant difference between responses to ChatGPT-generated and human-generated prompts for abstract words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 0.514465699273168\n",
      "P-Value: 0.61229856935533\n",
      "There is no statistically significant difference between the paired samples.\n",
      "Wilcoxon statistic: 106.0\n",
      "P-value: 0.5235109329223633\n",
      "There is no statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter results \n",
    "df = data[data['wordGroup'].isin(['abstract'])]\n",
    "\n",
    "#Filter results where TTS is not null\n",
    "true_df = df[df['guessed'] == True]\n",
    "\n",
    "#Filter results according to prompt provider\n",
    "gpt_df = true_df[true_df['generatedBy'].isin(['gpt'])]\n",
    "human_df = true_df[true_df['generatedBy'].isin(['human'])]\n",
    "\n",
    "#Filter TTS \n",
    "combined_df = gpt_df.merge(human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "GPT_TTS = combined_df['timeToSuccess_gpt']\n",
    "Human_TTS = combined_df['timeToSuccess_human']\n",
    "\n",
    "#Perform paired t-test\n",
    "t_statistic, p_value_t = stats.ttest_rel(GPT_TTS, Human_TTS)\n",
    "\n",
    "# Display the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value_t)\n",
    "\n",
    "# Determine if the difference is statistically significant\n",
    "if p_value_t < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")\n",
    "    \n",
    "#Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(GPT_TTS, Human_TTS)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3.2.3: In terms of time to succeed (TTS), there is a satistically significant difference between responses to ChatGPT-generated and human-generated prompts for words describing emotional states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistic: 5.0\n",
      "P-value: 0.009765625\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter results \n",
    "df = data[data['wordGroup'].isin(['emotion'])]\n",
    "\n",
    "#Filter results where TTS is not null\n",
    "true_df = df[df['guessed'] == True]\n",
    "\n",
    "#Filter results according to prompt provider\n",
    "gpt_df = true_df[true_df['generatedBy'].isin(['gpt'])]\n",
    "human_df = true_df[true_df['generatedBy'].isin(['human'])]\n",
    "\n",
    "#Filter TTS \n",
    "combined_df = gpt_df.merge(human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "GPT_TTS = combined_df['timeToSuccess_gpt']\n",
    "Human_TTS = combined_df['timeToSuccess_human']\n",
    "\n",
    "#Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(GPT_TTS, Human_TTS)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3.2.4: In terms of time to succeed (TTS), there is a satistically significant difference between responses to ChatGPT-generated and human-generated prompts for IT-specific words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistic: 4.0\n",
      "P-value: 0.02734375\n",
      "There is a statistically significant difference between the paired samples.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Taboo_Game_Data(v2).csv')\n",
    "\n",
    "#Filter results \n",
    "df = data[data['wordGroup'].isin(['IT'])]\n",
    "\n",
    "#Filter results where TTS is not null\n",
    "true_df = df[df['guessed'] == True]\n",
    "\n",
    "#Filter results according to prompt provider\n",
    "gpt_df = true_df[true_df['generatedBy'].isin(['gpt'])]\n",
    "human_df = true_df[true_df['generatedBy'].isin(['human'])]\n",
    "\n",
    "#Filter TTS \n",
    "combined_df = gpt_df.merge(human_df, on='Name', suffixes=('_gpt', '_human'))\n",
    "GPT_TTS = combined_df['timeToSuccess_gpt']\n",
    "Human_TTS = combined_df['timeToSuccess_human']\n",
    "\n",
    "#Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(GPT_TTS, Human_TTS)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results based on the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the paired samples.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
